{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dylan/RADIANT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from ipywidgets import interact, fixed\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "if os.path.basename(os.getcwd()) != \"RADIANT\":\n",
    "    print(\"Changing directory to RADIANT\")\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = \"MachineLearning/results/\"\n",
    "\n",
    "# direc = \"older/EPOCH_125/CLIPPING/FIRST/\" #? 30 epoch is good at .00025l 8lr\n",
    "# direc = \"older/EPOCH_125/CLIPPING/FIRST.LOFAR.NVSS/\" #? 30 epoch is good at .00025l 8lr\n",
    "# direc = \"older/EPOCH_125/CLIPPING/LOFAR/\" #? Would argue the same as above ^^^ (The heigher Test of 89 is overfitting)\n",
    "# direc = \"older/EPOCH_125/CLIPPING/NVSS/\" #? 30 epoch is good at .00025l 8lr\n",
    "\n",
    "# direc = \"older/EPOCH_125/NO_CLIPPING/FIRST/\" #? 50 epoch is good at .00025l 8lr\n",
    "# direc = \"older/EPOCH_125/NO_CLIPPING/FIRST.LOFAR.NVSS/\" #? Eish... too much overfitting everywhere according to the ratios\n",
    "# direc = \"older/EPOCH_125/NO_CLIPPING/LOFAR/\" #? 44 epoch is good at .00025l 8lr\n",
    "# direc = \"older/EPOCH_125/NO_CLIPPING/NVSS/\" #? 33-ish epoch is good at .00025l 8lr or 6lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc60e494b5849cab3f2b906c181bc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Experiment', options=('FIRST.LOFAR.NVSS_same_3000a_30e_0.000251l_0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_aclos_image(Experiment, Zoom, do_cut, Epoch_Cut=30)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_options = sorted(os.listdir(direc))\n",
    "\n",
    "loss_file = [x for x in os.listdir(direc + experiment_options[0]) if x.startswith(\"loss_fold\")][0]\n",
    "max_epochs = len(np.load(direc + experiment_options[0] + \"/\" + loss_file, allow_pickle=True).item()['accuracy'])\n",
    "\n",
    "def show_aclos_image(Experiment, Zoom, do_cut, Epoch_Cut = 30):\n",
    "    if Experiment.startswith(\"-\"):\n",
    "        return\n",
    "    directory = direc + Experiment\n",
    "    losses = []\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "\n",
    "        if filename.startswith(\"loss_fold\"):\n",
    "            loss = np.load(directory + \"/\" +filename, allow_pickle=True).item()\n",
    "            losses.append(loss)\n",
    "\n",
    "    blue = '#1f77b4'\n",
    "    orange = '#ff7f0e'\n",
    "    green = '#2ca02c'\n",
    "    purple = '#9467bd'\n",
    "\n",
    "    EPOCHS = len(loss['accuracy'])\n",
    "\n",
    "    train_acc = np.array([loss['accuracy'] for loss in losses])\n",
    "    train_acc_mean = np.mean(train_acc, axis=0)\n",
    "    train_acc_std = np.std(train_acc, axis=0)\n",
    "    val_acc = np.array([loss['val_accuracy'] for loss in losses])\n",
    "    val_acc_mean = np.mean(val_acc, axis=0)\n",
    "    val_acc_std = np.std(val_acc, axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    ax[0].plot(range(1, EPOCHS+1), train_acc_mean, label='Training Accuracy', color=blue)\n",
    "    ax[0].plot(range(1, EPOCHS+1), val_acc_mean, label='Validation Accuracy', color=orange)\n",
    "    for loss in losses:\n",
    "        ax[0].plot(range(1, EPOCHS+1), loss['accuracy'], alpha=0.1, color=blue)\n",
    "        ax[0].plot(range(1, EPOCHS+1), loss['val_accuracy'], alpha=0.1, color=orange)\n",
    "    ax[0].fill_between(range(1, EPOCHS+1), train_acc_mean - train_acc_std, train_acc_mean + train_acc_std, alpha=0.2,)\n",
    "    ax[0].fill_between(range(1, EPOCHS+1), val_acc_mean - val_acc_std, val_acc_mean + val_acc_std, alpha=0.2, color=orange)\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].set_title('Training and Validation Accuracy')\n",
    "    ax[0].legend()\n",
    "\n",
    "    train_loss = np.array([loss['loss'] for loss in losses])\n",
    "    train_loss_mean = np.mean(train_loss, axis=0)\n",
    "    train_loss_std = np.std(train_loss, axis=0)\n",
    "    val_loss = np.array([loss['val_loss'] for loss in losses])\n",
    "    val_loss_mean = np.mean(val_loss, axis=0)\n",
    "    val_loss_std = np.std(val_loss, axis=0)\n",
    "\n",
    "    ax[1].plot(range(1, EPOCHS+1), train_loss_mean, label='Training Loss', color=blue)\n",
    "    ax[1].plot(range(1, EPOCHS+1), val_loss_mean, label='Validation Loss', color=orange)\n",
    "    for loss in losses:\n",
    "        ax[1].plot(range(1, EPOCHS+1), loss['loss'], alpha=0.1, color=blue)\n",
    "        ax[1].plot(range(1, EPOCHS+1), loss['val_loss'], alpha=0.1, color=orange)\n",
    "    ax[1].fill_between(range(1, EPOCHS+1), train_loss_mean - train_loss_std, train_loss_mean + train_loss_std, alpha=0.2,)\n",
    "    ax[1].fill_between(range(1, EPOCHS+1), val_loss_mean - val_loss_std, val_loss_mean + val_loss_std, alpha=0.2, color=orange)\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].set_title(\"Training Validation Loss\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    ratios_loss = []\n",
    "    ratios_acc = []\n",
    "    for l in losses:\n",
    "        ratios_loss.append([l['loss'][i] / l['val_loss'][i] for i in range(EPOCHS)])\n",
    "        ratios_acc.append([l['accuracy'][i] / l['val_accuracy'][i] for i in range(EPOCHS)])\n",
    "    ratios_loss = np.array(ratios_loss)\n",
    "    ratios_acc = np.array(ratios_acc)\n",
    "\n",
    "    ratios_loss_mean = np.mean(ratios_loss, axis=0)\n",
    "    ratios_acc_mean = np.mean(ratios_acc, axis=0)\n",
    "    ratios_loss_std = np.std(ratios_loss, axis=0)\n",
    "    ratios_acc_std = np.std(ratios_acc, axis=0)\n",
    "\n",
    "    ax[2].plot(range(1, EPOCHS+1), ratios_loss_mean, label='Training/Validation Loss Ratio', color=green)\n",
    "    ax[2].plot(range(1, EPOCHS+1), ratios_acc_mean, label='Training/Validation Accuracy Ratio', color=purple)\n",
    "    for ratio_ac, ratio_lo in zip(ratios_acc,ratios_loss):\n",
    "        ax[2].plot(range(1, EPOCHS+1), ratio_ac, alpha=0.1, color=purple)\n",
    "        ax[2].plot(range(1, EPOCHS+1), ratio_lo, alpha=0.1, color=green)\n",
    "    ax[2].fill_between(range(1, EPOCHS+1), ratios_loss_mean - ratios_loss_std, ratios_loss_mean + ratios_loss_std, alpha=0.2,color=green)\n",
    "    ax[2].fill_between(range(1, EPOCHS+1), ratios_acc_mean - ratios_acc_std, ratios_acc_mean + ratios_acc_std, alpha=0.2, color=purple)\n",
    "    ax[2].set_xlabel('Epochs')\n",
    "    ax[2].set_ylabel('Ratio')\n",
    "    ax[2].set_title('Training/Validation Ratios')\n",
    "    ax[2].legend()\n",
    "    ax[2].axhline(y=1, color='black', linestyle='--')\n",
    "\n",
    "    if Zoom:\n",
    "        ax[0].set_ylim(.8,.91) \n",
    "        ax[1].set_ylim(0,10)\n",
    "        ax[2].set_ylim(0,1.0)\n",
    "    else:\n",
    "        ax[0].set_ylim(0,1)\n",
    "        ax[2].set_ylim(0,2.5)\n",
    "\n",
    "    if do_cut:\n",
    "\n",
    "        y_value = val_acc_mean[Epoch_Cut-1]\n",
    "        ax[0].axvline(x=Epoch_Cut, color='magenta', linestyle='--')\n",
    "        ax[0].axhline(y=y_value, color='magenta', linestyle='--')\n",
    "\n",
    "        ax[1].axvline(x=Epoch_Cut, color='magenta', linestyle='--')\n",
    "\n",
    "        y_value = ratios_loss_mean[Epoch_Cut-1]\n",
    "        ax[2].axvline(x=Epoch_Cut, color='magenta', linestyle='--')\n",
    "        ax[2].axhline(y=y_value, color='magenta', linestyle='--')\n",
    "\n",
    "\n",
    "    fig.suptitle(directory)\n",
    "    plt.show()\n",
    "\n",
    "interact(show_aclos_image, Experiment=experiment_options, do_cut=False, Epoch_Cut=(1,max_epochs) ,Zoom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd6e412d3044907aac19c83cc1878a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('test', 'val', 'train'), value='test'), Dropdow…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_scatter_image(dataset, show_matricies, get_data)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scc = SparseCategoricalCrossentropy()\n",
    "\n",
    "def show_scatter_image(dataset, show_matricies, get_data):\n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    coords = []\n",
    "\n",
    "    for folder in sorted(os.listdir(direc)):\n",
    "\n",
    "        details = folder.split(\"_\")\n",
    "        lr = float(details[-2][:-1]) \n",
    "        reg = float(details[-1][:-1])\n",
    "        lookup = np.load(direc + folder + \"/lookup.npy\", allow_pickle=True).item()\n",
    "\n",
    "        coords.append((lr, reg))\n",
    "\n",
    "        loss = []\n",
    "        accuracy = []\n",
    "        cms = []\n",
    "\n",
    "        for filename in sorted(os.listdir(direc + folder)):\n",
    "            if filename.startswith(\"y_pred_\"+dataset):\n",
    "                y_pred_soft = np.load(direc + folder + \"/\" + filename, allow_pickle=True)\n",
    "                \n",
    "                if dataset == \"test\":\n",
    "                    y_true_hard = np.load(direc + folder + \"/y_test.npy\", allow_pickle=True)\n",
    "                else:\n",
    "                    y_true_hard = np.load(direc + folder + \"/y_\" + dataset + \"_fold_\" + filename.split(\"_\")[3], allow_pickle=True)\n",
    "\n",
    "                labels = np.unique(y_true_hard)\n",
    "                \n",
    "                y_pred_hard = np.array([list(lookup.keys())[list(lookup.values()).index(np.argmax(x))] for x in y_pred_soft])\n",
    "                y_true_hard_encoded = np.array([lookup[x] for x in y_true_hard])\n",
    "                \n",
    "                loss.append(scc(y_true_hard_encoded, y_pred_soft))\n",
    "\n",
    "                accuracy.append(accuracy_score(y_true_hard, y_pred_hard))\n",
    "                cms.append(confusion_matrix(y_true_hard, y_pred_hard, normalize='true', labels=labels))\n",
    "\n",
    "\n",
    "        losses.append(np.mean(loss))\n",
    "        accuracies.append(np.mean(accuracy))\n",
    "        cm = np.mean(cms, axis=0)\n",
    "\n",
    "        if show_matricies == \"Confusion Matrix\":\n",
    "            plt.imshow(cm, cmap='viridis')\n",
    "            for i in range(cm.shape[0]):\n",
    "                for j in range(cm.shape[1]):\n",
    "                    if cm[i, j] > 0.5:\n",
    "                        colour = 'black'\n",
    "                    else:\n",
    "                        colour = 'white'\n",
    "                    plt.text(j, i, f\"{round(cm[i, j],2)}\", ha='center', va='center', color=colour)\n",
    "            plt.title(f\"{folder} : {round(accuracies[-1],2)}\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.xticks(range(len(labels)), labels)\n",
    "            plt.yticks(range(len(labels)), labels)\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "    if not coords:\n",
    "        print(\"No data found\")\n",
    "        return\n",
    "    \n",
    "    if show_matricies == \"Grid\":\n",
    "        fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "        im = ax[0].scatter(*zip(*coords), c=accuracies, cmap='viridis', s=170)\n",
    "        fig.colorbar(im, ax=ax[0])\n",
    "        ax[0].set_xlabel(\"Learning Rate\")\n",
    "        ax[0].set_ylabel(\"Regularization\")\n",
    "        ax[0].set_title(f\"{details[0]} Accuracy\")\n",
    "        ax[0].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
    "\n",
    "\n",
    "        im = ax[1].scatter(*zip(*coords), c=losses, cmap='viridis', s=170)\n",
    "        fig.colorbar(im, ax=ax[1])\n",
    "        ax[1].set_xlabel(\"Learning Rate\")\n",
    "        ax[1].set_ylabel(\"Regularization\")\n",
    "        ax[1].set_title(f\"{details[0]} Loss\")\n",
    "        ax[1].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
    "\n",
    "        for i, (ac, lo) in enumerate(zip(accuracies, losses)):\n",
    "            lo = str(round(lo,2))\n",
    "            ax[0].annotate(f\"{int(round(ac,2)*100)}\", (coords[i][0], coords[i][1]), ha='center', va='center')\n",
    "            ax[1].annotate(f\"{lo}\", (coords[i][0], coords[i][1]), ha='center', va='center')\n",
    "\n",
    "    if show_matricies == \"Contour\":\n",
    "        coords = np.array(coords)\n",
    "        learning_rate = coords[:, 0]\n",
    "        regularization = coords[:, 1]\n",
    "        from scipy.interpolate import griddata\n",
    "        min_lr, max_lr = min(learning_rate), max(learning_rate)\n",
    "        min_reg, max_reg = min(regularization), max(regularization)\n",
    "        number_of_points = 500j\n",
    "        grid_x, grid_y = np.mgrid[min_lr:max_lr:number_of_points, min_reg:max_reg:number_of_points]\n",
    "        \n",
    "        grid_z_ac = griddata(coords, accuracies, (grid_x, grid_y), method='cubic')\n",
    "        grid_z_lo = griddata(coords, losses, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "        fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "        contour = ax[0].contourf(grid_x, grid_y, grid_z_ac, levels=50, cmap='viridis')\n",
    "        fig.colorbar(contour, ax=ax[0])\n",
    "        ax[0].scatter(learning_rate, regularization, c=accuracies, edgecolors='w', linewidths=1)\n",
    "        ax[0].set_title('LOFAR Accuracy Contour Map')\n",
    "        ax[0].set_xlabel('Learning Rate')\n",
    "        ax[0].set_ylabel('Regularization')\n",
    "\n",
    "        contour = ax[1].contourf(grid_x, grid_y, grid_z_lo, levels=50, cmap='viridis')\n",
    "        fig.colorbar(contour, ax=ax[1])\n",
    "        ax[1].scatter(learning_rate, regularization, c=losses, edgecolors='w', linewidths=1)\n",
    "        ax[1].set_title('LOFAR Loss Contour Map')\n",
    "        ax[1].set_xlabel('Learning Rate')\n",
    "        ax[1].set_ylabel('Regularization')\n",
    "        plt.show()\n",
    "\n",
    "    if get_data:\n",
    "        return accuracies, losses, coords\n",
    "    \n",
    "interact(show_scatter_image, dataset=[\"test\",\"val\",\"train\"], show_matricies=[\"Grid\", \"Contour\",\"Confusion Matrix\"], get_data=fixed(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d11af89f42c422588127e738dac905a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='numerator', options=('train', 'val', 'test'), value='train'), Drop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_ratios(numerator, denominator, invert_ac=False, invert_lo=False)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_ratios(numerator, denominator, invert_ac=False, invert_lo=False):\n",
    "    num_ac, num_lo, num_coords = show_scatter_image(numerator, get_data=True, show_matricies=None)\n",
    "    den_ac, den_lo, den_coords = show_scatter_image(denominator, get_data=True, show_matricies=None)\n",
    "\n",
    "    if num_coords != den_coords:\n",
    "        raise ValueError(\"Coords need to match. Something went wrong.\")\n",
    "\n",
    "    numerator_ac = numerator\n",
    "    numerator_lo = numerator\n",
    "    denominator_ac = denominator\n",
    "    denominator_lo = denominator\n",
    "\n",
    "    if invert_ac:\n",
    "        den_ac, num_ac = num_ac, den_ac\n",
    "        numerator_ac, denominator_ac = denominator_ac, numerator_ac\n",
    "    if invert_lo:\n",
    "        den_lo, num_lo = num_lo, den_lo\n",
    "        numerator_lo, denominator_lo = denominator_lo, numerator_lo\n",
    "\n",
    "    ratios_ac = [num_ac[i] / den_ac[i] for i in range(len(num_ac))]\n",
    "    ratios_lo = [num_lo[i] / den_lo[i] for i in range(len(num_lo))]\n",
    "\n",
    "    coords = [(ac, lo) for ac, lo in zip(ratios_ac, ratios_lo)]\n",
    "    distances = [np.sqrt((1-ac)**2 + (1-lo)**2) for ac, lo in coords]\n",
    "\n",
    "    plt.scatter(*zip(*coords), s=170, marker='.')\n",
    "    plt.scatter(1, 1, color='red', s=170, marker='.')\n",
    "    plt.vlines(1, colors='#AAA5', linestyles='--', ymin=min(ratios_lo), ymax=max(ratios_lo))\n",
    "    plt.hlines(1, colors='#AAA5', linestyles='--', xmin=min(ratios_ac), xmax=max(ratios_ac))\n",
    "    plt.xlabel(f\"Accuracy ({numerator_ac}/{denominator_ac})\")\n",
    "    plt.ylabel(f\"Loss ({numerator_lo}/{denominator_lo})\")\n",
    "    survey = os.listdir(direc)[0].split(\"_\")[0]\n",
    "    plt.title(f\"{survey} Ratios\")\n",
    "    plt.show()\n",
    "\n",
    "    args = np.argsort(distances)\n",
    "    for number, i in enumerate(args):\n",
    "        print(f\"{number+1:2d} | Distance: {distances[i]:.2f}  A_Ratio: {ratios_ac[i]:.2f}  L_Ratio: {ratios_lo[i]:.2f}  ( {num_coords[i][0]:.2e} lr, {num_coords[i][1]:.2e} reg )  Accuracy: {num_ac[i]:.2f}/{den_ac[i]:.2f}    \")\n",
    "\n",
    "\n",
    "interact(show_ratios, numerator=[\"train\",\"val\",\"test\"], denominator=[\"val\",\"train\",\"test\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
